
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler

df = pd.read_csv('../data/googleplaystore.csv')

print("Форма датасета:", df.shape)
df.head()
print("Количество пропущенных значений по столбцам:")
print(df.isnull().sum())

print("\nТипы данных:")
print(df.dtypes)

print("\nСтатистическое описание числовых данных:")
print(df.describe())

# Предобработка данных

df = df[df['Installs'] != 'Free']
df['Installs'] = df['Installs'].str.replace('+', '').str.replace(',', '').astype(float)
df['Price'] = df['Price'].str.replace('$', '').astype(float)

le = LabelEncoder()
categorical_cols = ['Category', 'Type', 'Content Rating', 'Genres', 'Android Ver']
for col in categorical_cols:
    df[col] = df[col].fillna('Unknown')
    df[col] = le.fit_transform(df[col])

df['Rating'] = df['Rating'].fillna(df['Rating'].mean())

df['High_Rating'] = (df['Rating'] >= 4.0).astype(int)

df['Size'] = df['Size'].replace('Varies with device', np.nan)
df['Size'] = df['Size'].str.replace('M', '').str.replace('k', 'e-3').astype(float)
df['Size'] = df['Size'].fillna(df['Size'].median())

df['Reviews'] = df['Reviews'].astype(float)

df['Last Updated'] = pd.to_datetime(df['Last Updated'], format='%B %d, %Y', errors='coerce')
df['Days_Since_Update'] = (pd.Timestamp('2018-08-05') - df['Last Updated']).dt.days
df['Days_Since_Update'] = df['Days_Since_Update'].fillna(df['Days_Since_Update'].median())

numeric_features = ['Days_Since_Update', 'Size', 'Installs', 'Price', 'Reviews']

features = numeric_features + categorical_cols

X = df[features]
y = df['High_Rating']

print(f"Форма X: {X.shape}, форма y: {y.shape}")
print(f"Распределение целевой переменной: {y.value_counts().to_dict()}")
print("\nПроверка на пропуски после предобработки:")
print(X.isnull().sum())

# Масштабирование числовых признаков
scaler = StandardScaler()
X_scaled = X.copy()
X_scaled[numeric_features] = scaler.fit_transform(X_scaled[numeric_features])

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

print(f"Размер обучающей выборки: {X_train.shape}")
print(f"Размер тестовой выборки: {X_test.shape}")

plt.figure(figsize=(10, 6))
sns.boxplot(x='High_Rating', y='Size', data=df)
plt.title('Размер приложения в зависимости от рейтинга')
plt.xlabel('Высокий рейтинг (1 - да, 0 - нет)')
plt.ylabel('Размер (МБ)')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='High_Rating', y='Installs', data=df)
plt.title('Количество установок в зависимости от рейтинга')
plt.yscale('log')
plt.xlabel('Высокий рейтинг (1 - да, 0 - нет)')
plt.ylabel('Количество установок (лог. масштаб)')
plt.show()


# Построение модели дерева решений
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)

dt_y_pred = dt_classifier.predict(X_test)

dt_accuracy = accuracy_score(y_test, dt_y_pred)
dt_precision = precision_score(y_test, dt_y_pred)
dt_recall = recall_score(y_test, dt_y_pred)
dt_f1 = f1_score(y_test, dt_y_pred)

print("Результаты модели дерева решений:")
print(f"Точность (Accuracy): {dt_accuracy:.4f}")
print(f"Точность (Precision): {dt_precision:.4f}")
print(f"Полнота (Recall): {dt_recall:.4f}")
print(f"F1-мера: {dt_f1:.4f}")

# Матрица ошибок
plt.figure(figsize=(8, 6))
dt_cm = confusion_matrix(y_test, dt_y_pred)
sns.heatmap(dt_cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Низкий рейтинг', 'Высокий рейтинг'],
            yticklabels=['Низкий рейтинг', 'Высокий рейтинг'])
plt.title('Матрица ошибок модели дерева решений')
plt.xlabel('Предсказанный класс')
plt.ylabel('Истинный класс')
plt.show()

print("\nОтчет о классификации:")
print(classification_report(y_test, dt_y_pred, target_names=['Низкий рейтинг', 'Высокий рейтинг']))

# Построение модели градиентного бустинга
gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gb_classifier.fit(X_train, y_train)

gb_y_pred = gb_classifier.predict(X_test)

gb_accuracy = accuracy_score(y_test, gb_y_pred)
gb_precision = precision_score(y_test, gb_y_pred)
gb_recall = recall_score(y_test, gb_y_pred)
gb_f1 = f1_score(y_test, gb_y_pred)

print("Результаты модели градиентного бустинга:")
print(f"Точность (Accuracy): {gb_accuracy:.4f}")
print(f"Точность (Precision): {gb_precision:.4f}")
print(f"Полнота (Recall): {gb_recall:.4f}")
print(f"F1-мера: {gb_f1:.4f}")

# Матрица ошибок
plt.figure(figsize=(8, 6))
gb_cm = confusion_matrix(y_test, gb_y_pred)
sns.heatmap(gb_cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Низкий рейтинг', 'Высокий рейтинг'],
            yticklabels=['Низкий рейтинг', 'Высокий рейтинг'])
plt.title('Матрица ошибок модели градиентного бустинга')
plt.xlabel('Предсказанный класс')
plt.ylabel('Истинный класс')
plt.show()

print("\nОтчет о классификации:")
print(classification_report(y_test, gb_y_pred, target_names=['Низкий рейтинг', 'Высокий рейтинг']))


# Сравнение важности признаков в моделях

dt_feature_importances = pd.DataFrame({'feature': X.columns,
                                      'importance': dt_classifier.feature_importances_})
dt_feature_importances = dt_feature_importances.sort_values('importance', ascending=False).head(10)

gb_feature_importances = pd.DataFrame({'feature': X.columns,
                                      'importance': gb_classifier.feature_importances_})
gb_feature_importances = gb_feature_importances.sort_values('importance', ascending=False).head(10)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.barplot(x='importance', y='feature', data=dt_feature_importances)
plt.title('Важность признаков (Дерево решений)')
plt.tight_layout()

plt.subplot(1, 2, 2)
sns.barplot(x='importance', y='feature', data=gb_feature_importances)
plt.title('Важность признаков (Градиентный бустинг)')
plt.tight_layout()
plt.show()

# Сравнение результатов моделей

# Создание DataFrame для сравнения
model_comparison = pd.DataFrame({
    'Метрика': ['Accuracy', 'Precision', 'Recall', 'F1-score'],
    'Дерево решений': [dt_accuracy, dt_precision, dt_recall, dt_f1],
    'Градиентный бустинг': [gb_accuracy, gb_precision, gb_recall, gb_f1]
})

print("Сравнение моделей:")
print(model_comparison)

# Визуализация сравнения метрик
plt.figure(figsize=(10, 6))
model_comparison_melted = model_comparison.melt(id_vars=['Метрика'],
                                               var_name='Модель',
                                               value_name='Значение')
sns.barplot(x='Метрика', y='Значение', hue='Модель', data=model_comparison_melted)
plt.ylim(0, 1)
plt.title('Сравнение метрик качества моделей')
plt.ylabel('Значение метрики')
plt.show()

# Выводы о построенных моделях
print("""
Выводы:

1. Для оценки качества моделей были использованы следующие метрики:
   - Accuracy (Точность) - доля правильных ответов модели.
   - Precision (Точность) - доля объектов, действительно принадлежащих классу, среди всех объектов, которые система отнесла к этому классу.
   - Recall (Полнота) - доля найденных классификатором объектов, принадлежащих классу, относительно всех объектов этого класса.
   - F1-score - гармоническое среднее между точностью и полнотой, позволяет оценить качество модели по обеим метрикам.

2. Выбор метрик обусловлен:
   - Необходимостью комплексной оценки качества классификации
   - Наличием дисбаланса классов в данных (как видно из распределения целевой переменной)
   - Важностью оценки как точности, так и полноты классификации

3. Сравнение моделей:
   - Градиентный бустинг показал лучшие результаты почти по всем метрикам
   - Обе модели достаточно хорошо справляются с задачей классификации приложений по рейтингу
   - Наиболее важными признаками для предсказания рейтинга являются количество отзывов и установок

4. Была проведена следующая предобработка данных:
   - Заполнение пропущенных значений
   - Кодирование категориальных признаков
   - Масштабирование числовых признаков
   - Преобразование строковых значений в числовые
""")
